{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel,RFECV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pydot\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tools import data_prep\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2903: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41432 entries, 0 to 41475\n",
      "Data columns (total 31 columns):\n",
      "PurchaseID                           41432 non-null int64\n",
      "PurchaseTimestamp                    41432 non-null int64\n",
      "PurchaseDate                         41432 non-null object\n",
      "Auction                              41432 non-null object\n",
      "VehYear                              41432 non-null float64\n",
      "Make                                 41432 non-null object\n",
      "Color                                41432 non-null object\n",
      "Transmission                         41432 non-null object\n",
      "WheelTypeID                          41432 non-null object\n",
      "WheelType                            41380 non-null object\n",
      "VehOdo                               41432 non-null float64\n",
      "Nationality                          41432 non-null object\n",
      "Size                                 41432 non-null object\n",
      "TopThreeAmericanName                 41432 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    41416 non-null object\n",
      "MMRAcquisitionAuctionCleanPrice      41429 non-null object\n",
      "MMRAcquisitionRetailAveragePrice     41429 non-null object\n",
      "MMRAcquisitonRetailCleanPrice        41327 non-null object\n",
      "MMRCurrentAuctionAveragePrice        41429 non-null object\n",
      "MMRCurrentAuctionCleanPrice          41429 non-null object\n",
      "MMRCurrentRetailAveragePrice         41409 non-null object\n",
      "MMRCurrentRetailCleanPrice           41409 non-null object\n",
      "MMRCurrentRetailRatio                41116 non-null object\n",
      "PRIMEUNIT                            41432 non-null object\n",
      "AUCGUART                             41432 non-null object\n",
      "VNST                                 41432 non-null object\n",
      "VehBCost                             41432 non-null object\n",
      "IsOnlineSale                         41432 non-null object\n",
      "WarrantyCost                         41432 non-null float64\n",
      "ForSale                              41432 non-null object\n",
      "IsBadBuy                             41432 non-null int64\n",
      "dtypes: float64(3), int64(3), object(25)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data_prep()\n",
    "# separating the y_label -- prediction set\n",
    "y = df['IsBadBuy']\n",
    "\n",
    "# X -features are all column except y\n",
    "X = df.drop(['IsBadBuy'], axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# setting random state\n",
    "# .as_matrix removed replaced with .values\n",
    "# train test 70 / 30 percent\n",
    "rs = 10\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.30, stratify=y, random_state=rs)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model construction and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9665823458926908\n",
      "Test accuracy: 0.7996272134203168\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.84      0.81      1609\n",
      "          1       0.83      0.76      0.79      1610\n",
      "\n",
      "avg / total       0.80      0.80      0.80      3219\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=10, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9660497936360005\n",
      "Test accuracy: 0.7958993476234856\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.81      0.80      1609\n",
      "          1       0.81      0.78      0.79      1610\n",
      "\n",
      "avg / total       0.80      0.80      0.80      3219\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=10, shuffle=True,\n",
      "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter=100, random_state=rs)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8599387564904807\n",
      "Test accuracy: 0.8266542404473439\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.84      1609\n",
      "          1       0.89      0.75      0.81      1610\n",
      "\n",
      "avg / total       0.83      0.83      0.83      3219\n",
      "\n",
      "{'hidden_layer_sizes': (5,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(x,) for x in range(5, 86, 20)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8499534016775396\n",
      "Test accuracy: 0.833488661074868\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.92      0.85      1609\n",
      "          1       0.90      0.75      0.82      1610\n",
      "\n",
      "avg / total       0.84      0.83      0.83      3219\n",
      "\n",
      "{'hidden_layer_sizes': (3,)}\n"
     ]
    }
   ],
   "source": [
    "# new parameters\n",
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8528824390893356\n",
      "Test accuracy: 0.8365952159055607\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.92      0.85      1609\n",
      "          1       0.91      0.75      0.82      1610\n",
      "\n",
      "avg / total       0.85      0.84      0.84      3219\n",
      "\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (3,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# list columns to be transformed\n",
    "columns_to_transform = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "                        'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice']\n",
    "\n",
    "# copy the dataframe\n",
    "df_log = df.copy()\n",
    "\n",
    "# transform the columns with np.log\n",
    "for col in columns_to_transform:\n",
    "    df_log[col] = df_log[col].apply(lambda x: x+1)\n",
    "    df_log[col] = df_log[col].apply(np.log)\n",
    "    \n",
    "# create X, y and train test data partitions\n",
    "y_log = df_log['IsBadBuy']\n",
    "X_log = df_log.drop(['IsBadBuy'], axis=1)\n",
    "X_mat_log = X_log.as_matrix()\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_mat_log, y_log, test_size=0.3, stratify=y_log, \n",
    "                                                                    random_state=rs)\n",
    "\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_log, y_train_log)\n",
    "X_test_log = scaler_log.transform(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8507522300625749\n",
      "Test accuracy: 0.8288288288288288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.92      0.84      1609\n",
      "          1       0.90      0.74      0.81      1610\n",
      "\n",
      "avg / total       0.84      0.83      0.83      3219\n",
      "\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (3,)}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_log, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(X_train_log, y_train_log)\n",
    "\n",
    "print(rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform log \n",
    "X_train_rfe = rfe.transform(X_train_log)\n",
    "X_test_rfe = rfe.transform(X_test_log)\n",
    "\n",
    "# step = int((X_train_rfe.shape[1] + 5)/5);\n",
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_rfe, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_rfe, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_rfe, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_rfe)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(3, 8),\n",
    "          'min_samples_leaf': range(20, 61, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "analyse_feature_importance(cv.best_estimator_, X_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train)\n",
    "X_test_sel_model = selectmodel.transform(X_test)\n",
    "\n",
    "print(X_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel_model, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel_model, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel_model, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test_sel_model)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search CV for decision tree\n",
    "params_dt = {'criterion': ['gini'],\n",
    "          'max_depth': range(2, 5),\n",
    "          'min_samples_leaf': range(40, 61, 5)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params_dt, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "dt_model = cv.best_estimator_\n",
    "print(dt_model)\n",
    "\n",
    "# grid search CV for logistic regression\n",
    "params_log_reg = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params_log_reg, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "log_reg_model = cv.best_estimator_\n",
    "print(log_reg_model)\n",
    "\n",
    "# grid search CV for NN\n",
    "params_nn = {'hidden_layer_sizes': [(3,), (5,), (7,), (9,)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params_nn, estimator=MLPClassifier(max_iter=500, random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "nn_model = cv.best_estimator_\n",
    "print(nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score on test for DT:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Accuracy score on test for logistic regression:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Accuracy score on test for NN:\", accuracy_score(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
