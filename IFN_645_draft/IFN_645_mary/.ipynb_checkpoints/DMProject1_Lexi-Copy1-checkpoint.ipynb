{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tools import data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2903: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41432 entries, 0 to 41475\n",
      "Data columns (total 31 columns):\n",
      "PurchaseID                           41432 non-null int64\n",
      "PurchaseTimestamp                    41432 non-null int64\n",
      "PurchaseDate                         41432 non-null object\n",
      "Auction                              41432 non-null object\n",
      "VehYear                              41432 non-null float64\n",
      "Make                                 41432 non-null object\n",
      "Color                                41432 non-null object\n",
      "Transmission                         41432 non-null object\n",
      "WheelTypeID                          41432 non-null object\n",
      "WheelType                            41380 non-null object\n",
      "VehOdo                               41432 non-null float64\n",
      "Nationality                          41432 non-null object\n",
      "Size                                 41432 non-null object\n",
      "TopThreeAmericanName                 41432 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    41416 non-null object\n",
      "MMRAcquisitionAuctionCleanPrice      41429 non-null object\n",
      "MMRAcquisitionRetailAveragePrice     41429 non-null object\n",
      "MMRAcquisitonRetailCleanPrice        41327 non-null object\n",
      "MMRCurrentAuctionAveragePrice        41429 non-null object\n",
      "MMRCurrentAuctionCleanPrice          41429 non-null object\n",
      "MMRCurrentRetailAveragePrice         41409 non-null object\n",
      "MMRCurrentRetailCleanPrice           41409 non-null object\n",
      "MMRCurrentRetailRatio                41116 non-null object\n",
      "PRIMEUNIT                            41432 non-null object\n",
      "AUCGUART                             41432 non-null object\n",
      "VNST                                 41432 non-null object\n",
      "VehBCost                             41432 non-null object\n",
      "IsOnlineSale                         41432 non-null object\n",
      "WarrantyCost                         41432 non-null float64\n",
      "ForSale                              41432 non-null object\n",
      "IsBadBuy                             41432 non-null int64\n",
      "dtypes: float64(3), int64(3), object(25)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "X, y = data_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#labelEncoder = LabelEncoder()\n",
    "\n",
    "#categorical_feature_mask = df_final.dtypes==object\n",
    "#categorical_cols = df_final.columns[categorical_feature_mask].tolist()\n",
    "#df_final[categorical_cols] = df_final[categorical_cols].apply(lambda col: labelEncoder.fit_transform(col))\n",
    "#df_final.values[:,7] = labelEncoder.fit_transform(df_final.values[:,7])\n",
    "\n",
    "#df_final\n",
    "\n",
    "# set the random seed - consistent\n",
    "rs = 10\n",
    "\n",
    "# train test split\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling\n",
      "-------------\n",
      "Variable #0: min 0.0, max 1.0, mean 0.04 and std dev 0.19\n",
      "Variable #1: min 577.0, max 480444.0, mean 72384.47 and std dev 14998.09\n",
      "Variable #2: min 0.0, max 33543.0, mean 5946.68 and std dev 2568.24\n",
      "Variable #3: min 0.0, max 36701.0, mean 7178.38 and std dev 2844.14\n",
      "Variable #4: min 0.0, max 36726.0, mean 8228.66 and std dev 3252.30\n",
      "After scaling\n",
      "-------------\n",
      "Variable #0: min -0.1949472296104162, max 5.129593285312624, mean 0.00 and std dev 1.00\n",
      "Variable #1: min -4.7877757075676, max 27.207441862755417, mean 0.00 and std dev 1.00\n",
      "Variable #2: min -2.315464923295065, max 10.745211522747928, mean -0.00 and std dev 1.00\n",
      "Variable #3: min -2.52391795848795, max 10.38015377969556, mean 0.00 and std dev 1.00\n",
      "Variable #4: min -2.530107339282775, max 8.762218203273306, mean -0.00 and std dev 1.00\n"
     ]
    }
   ],
   "source": [
    "# initialise a standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# visualise min, max, mean and standard dev of data before scaling\n",
    "print(\"Before scaling\\n-------------\")\n",
    "for i in range(5):\n",
    "    col = X_train[:,i]\n",
    "    print(\"Variable #{}: min {}, max {}, mean {:.2f} and std dev {:.2f}\".\n",
    "          format(i, min(col), max(col), np.mean(col), np.std(col)))\n",
    "\n",
    "# learn the mean and std.dev of variables from training data\n",
    "# then use the learned values to transform training data\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "print(\"After scaling\\n-------------\")\n",
    "for i in range(5):\n",
    "    col = X_train[:,i]\n",
    "    print(\"Variable #{}: min {}, max {}, mean {:.2f} and std dev {:.2f}\".\n",
    "          format(i, min(col), max(col), np.mean(col), np.std(col)))\n",
    "\n",
    "# use the statistic that you learned from training to transform test data\n",
    "# NEVER learn from test data, this is supposed to be a set of dataset\n",
    "# that the model has never seen before\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=10, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=rs)\n",
    "\n",
    "# fit it to training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825455997869791\n",
      "Test accuracy: 0.8232370301335818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84      1609\n",
      "          1       0.90      0.73      0.80      1610\n",
      "\n",
      "avg / total       0.84      0.82      0.82      3219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and test accuracy\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "# classification report on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transmission : -0.06822026349210418\n",
      "VehOdo : 0.15152118438613474\n",
      "MMRAcquisitionAuctionAveragePrice : -1.3802951674635233\n",
      "MMRAcquisitionAuctionCleanPrice : 0.5924495249311702\n",
      "MMRAcquisitionRetailAveragePrice : 1.2258851395157986\n",
      "MMRAcquisitonRetailCleanPrice : -0.05321443060115353\n",
      "MMRCurrentAuctionAveragePrice : 0.68008763880614\n",
      "MMRCurrentAuctionCleanPrice : -0.3412170106727569\n",
      "MMRCurrentRetailAveragePrice : -0.0921957265534876\n",
      "MMRCurrentRetailCleanPrice : -0.41957346998343953\n",
      "MMRCurrentRetailRatio : -0.06541074269927825\n",
      "VehBCost : -0.37490759532762263\n",
      "WarrantyCost : 0.08317583122008965\n",
      "Auction_ADESA : 2.06569972872485\n",
      "Auction_MANHEIM : -0.8391635647189372\n",
      "Auction_OTHER : -0.9037717245362028\n",
      "VehYear_2001.0 : 0.22098137368059795\n",
      "VehYear_2002.0 : 0.26684034588858735\n",
      "VehYear_2003.0 : 0.2373170329925653\n",
      "VehYear_2004.0 : 0.17166976022239985\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns\n",
    "coef = model.coef_[0]\n",
    "\n",
    "# limit to 20 features, you can comment the following line to print out everything\n",
    "coef = coef[:20]\n",
    "\n",
    "for i in range(len(coef)):\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auction_ADESA : 2.06569972872485\n",
      "VNST_AZ : 1.8048255117114467\n",
      "MMRAcquisitionAuctionAveragePrice : -1.3802951674635233\n",
      "VNST_OK : 1.270164390498947\n",
      "MMRAcquisitionRetailAveragePrice : 1.2258851395157986\n",
      "Auction_OTHER : -0.9037717245362028\n",
      "Auction_MANHEIM : -0.8391635647189372\n",
      "VNST_CO : -0.8096213013663035\n",
      "MMRCurrentAuctionAveragePrice : 0.68008763880614\n",
      "VNST_PA : 0.669406061904637\n",
      "VehYear_2008.0 : -0.6623714131764916\n",
      "MMRAcquisitionAuctionCleanPrice : 0.5924495249311702\n",
      "VNST_MO : 0.570462431964441\n",
      "VNST_TX : -0.5348395061384371\n",
      "VNST_FL : -0.48501297235417323\n",
      "VNST_GA : -0.4633650440807044\n",
      "VNST_VA : -0.4547188987170395\n",
      "VNST_MS : 0.4284652650741305\n",
      "MMRCurrentRetailCleanPrice : -0.41957346998343953\n",
      "VNST_NJ : 0.37943657146570997\n"
     ]
    }
   ],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "coef = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825455997869791\n",
      "Test accuracy: 0.8232370301335818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84      1609\n",
      "          1       0.90      0.73      0.80      1610\n",
      "\n",
      "avg / total       0.84      0.82      0.82      3219\n",
      "\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
