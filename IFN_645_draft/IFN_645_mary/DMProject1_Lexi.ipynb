{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tools import data_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Data from data_prep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2903: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41432 entries, 0 to 41475\n",
      "Data columns (total 31 columns):\n",
      "PurchaseID                           41432 non-null int64\n",
      "PurchaseTimestamp                    41432 non-null int64\n",
      "PurchaseDate                         41432 non-null object\n",
      "Auction                              41432 non-null object\n",
      "VehYear                              41432 non-null float64\n",
      "Make                                 41432 non-null object\n",
      "Color                                41432 non-null object\n",
      "Transmission                         41432 non-null object\n",
      "WheelTypeID                          41432 non-null object\n",
      "WheelType                            41380 non-null object\n",
      "VehOdo                               41432 non-null float64\n",
      "Nationality                          41432 non-null object\n",
      "Size                                 41432 non-null object\n",
      "TopThreeAmericanName                 41432 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    41416 non-null object\n",
      "MMRAcquisitionAuctionCleanPrice      41429 non-null object\n",
      "MMRAcquisitionRetailAveragePrice     41429 non-null object\n",
      "MMRAcquisitonRetailCleanPrice        41327 non-null object\n",
      "MMRCurrentAuctionAveragePrice        41429 non-null object\n",
      "MMRCurrentAuctionCleanPrice          41429 non-null object\n",
      "MMRCurrentRetailAveragePrice         41409 non-null object\n",
      "MMRCurrentRetailCleanPrice           41409 non-null object\n",
      "MMRCurrentRetailRatio                41116 non-null object\n",
      "PRIMEUNIT                            41432 non-null object\n",
      "AUCGUART                             41432 non-null object\n",
      "VNST                                 41432 non-null object\n",
      "VehBCost                             41432 non-null object\n",
      "IsOnlineSale                         41432 non-null object\n",
      "WarrantyCost                         41432 non-null float64\n",
      "ForSale                              41432 non-null object\n",
      "IsBadBuy                             41432 non-null int64\n",
      "dtypes: float64(3), int64(3), object(25)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data_prep()\n",
    "y = df['IsBadBuy']\n",
    "X = df.drop(['IsBadBuy'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#labelEncoder = LabelEncoder()\n",
    "\n",
    "#categorical_feature_mask = df_final.dtypes==object\n",
    "#categorical_cols = df_final.columns[categorical_feature_mask].tolist()\n",
    "#df_final[categorical_cols] = df_final[categorical_cols].apply(lambda col: labelEncoder.fit_transform(col))\n",
    "#df_final.values[:,7] = labelEncoder.fit_transform(df_final.values[:,7])\n",
    "\n",
    "#df_final\n",
    "\n",
    "# set the random seed - consistent\n",
    "rs = 10\n",
    "\n",
    "# train test split\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scalering value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# learn the mean and std.dev of variables from training data\n",
    "# then use the learned values to transform training data\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "# use the statistic that you learned from training to transform test data\n",
    "# NEVER learn from test data, this is supposed to be a set of dataset\n",
    "# that the model has never seen before\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=10, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=rs)\n",
    "\n",
    "# fit it to training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate first Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825455997869791\n",
      "Test accuracy: 0.8232370301335818\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84      1609\n",
      "          1       0.90      0.73      0.80      1610\n",
      "\n",
      "avg / total       0.84      0.82      0.82      3219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and test accuracy\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "# classification report on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get the top 20 most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auction_ADESA                      : 2.06569972872485\n",
      "VNST_AZ                            : 1.8048255117114467\n",
      "MMRAcquisitionAuctionAveragePrice  : -1.3802951674635233\n",
      "VNST_OK                            : 1.270164390498947\n",
      "MMRAcquisitionRetailAveragePrice   : 1.2258851395157986\n",
      "Auction_OTHER                      : -0.9037717245362028\n",
      "Auction_MANHEIM                    : -0.8391635647189372\n",
      "VNST_CO                            : -0.8096213013663035\n",
      "MMRCurrentAuctionAveragePrice      : 0.68008763880614\n",
      "VNST_PA                            : 0.669406061904637\n",
      "VehYear_2008.0                     : -0.6623714131764916\n",
      "MMRAcquisitionAuctionCleanPrice    : 0.5924495249311702\n",
      "VNST_MO                            : 0.570462431964441\n",
      "VNST_TX                            : -0.5348395061384371\n",
      "VNST_FL                            : -0.48501297235417323\n",
      "VNST_GA                            : -0.4633650440807044\n",
      "VNST_VA                            : -0.4547188987170395\n",
      "VNST_MS                            : 0.4284652650741305\n",
      "MMRCurrentRetailCleanPrice         : -0.41957346998343953\n",
      "VNST_NJ                            : 0.37943657146570997\n"
     ]
    }
   ],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "coef = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(f\"{feature_names[i]:<35}: {coef[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8253228598056185\n",
      "Test accuracy: 0.8235476856166511\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84      1609\n",
      "          1       0.90      0.73      0.81      1610\n",
      "\n",
      "avg / total       0.84      0.82      0.82      3219\n",
      "\n",
      "{'C': 1.4111, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "#params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "#params = {'C' : [1.4111, 1.4112, 1.4113, 1.4114], 'penalty': ['l1','l2'],\n",
    "          #'dual':[False], 'multi_class':['ovr'], 'solver':[ 'liblinear', 'sag', 'saga']},\n",
    "params = {'penalty':['l1','l2'],'C':[1.4111],'solver':['liblinear'],'multi_class':['ovr']},\n",
    "{'penalty':['l2'],'C':[1.4111],'solver':['lbfgs'],'multi_class':['ovr','multinomial']}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Get Log of each variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe\n",
    "df_log = df.copy()\n",
    "#X_log, y_log = data_prep()\n",
    "y_log = df_log['IsBadBuy']\n",
    "X_log = df_log.drop(['IsBadBuy'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns to be transformed\n",
    "columns_to_transform = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice',\n",
    "                        'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice','MMRCurrentRetailCleanPrice','VehBCost']\n",
    "\n",
    "# transform the columns with np.log\n",
    "for col in columns_to_transform:\n",
    "    X_log[col] = X_log[col].apply(lambda x: x+1)\n",
    "    X_log[col] = X_log[col].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\conda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create X, y and train test data partitions\n",
    "X_mat_log = X_log.as_matrix()\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_mat_log, y_log, test_size=0.3, stratify=y_log, \n",
    "                                                                    random_state=rs)\n",
    "\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_log, y_train_log)\n",
    "X_test_log = scaler_log.transform(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8250565836772733\n",
      "Test accuracy: 0.8213730972351662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.84      1609\n",
      "          1       0.89      0.73      0.80      1610\n",
      "\n",
      "avg / total       0.83      0.82      0.82      3219\n",
      "\n",
      "{'C': 1.4111, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'penalty':['l1','l2'],'C':[1.4111],'solver':['liblinear'],'multi_class':['ovr']},\n",
    "{'penalty':['l2'],'C':[1.4111],'solver':['lbfgs'],'multi_class':['ovr','multinomial']}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_log, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Use RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature set 126\n",
      "Number of features after elimination 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(X_train, y_train) # run the RFECV\n",
    "\n",
    "# comparing how many variables before and after\n",
    "print(\"Original feature set\", X_train.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = rfe.transform(X_train)\n",
    "X_test_sel = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run another GridSearchCV and test if the new input set improves the model performance.\n",
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test_sel)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE + LOg reduction\n",
    "# running RFE + log transformation\n",
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs), cv=10)\n",
    "rfe.fit(X_train_log, y_train_log) # run the RFECV on log transformed dataset\n",
    "\n",
    "# comparing how many variables before and after\n",
    "print(\"Original feature set\", X_train_log.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)\n",
    "\n",
    "# select features from log transformed dataset\n",
    "X_train_sel_log = rfe.transform(X_train_log)\n",
    "X_test_sel_log = rfe.transform(X_test_log)\n",
    "\n",
    "# init grid search CV on transformed dataset\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel_log, y_train_log)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel_log, y_test_log))\n",
    "\n",
    "y_pred_log = cv.predict(X_test_sel_log)\n",
    "print(classification_report(y_test_log, y_pred_log))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "coef = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
