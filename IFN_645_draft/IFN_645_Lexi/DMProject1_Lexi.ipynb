{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from tools import data_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Data from data_prep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41432 entries, 0 to 41475\n",
      "Data columns (total 31 columns):\n",
      "PurchaseID                           41432 non-null int64\n",
      "PurchaseTimestamp                    41432 non-null int64\n",
      "PurchaseDate                         41432 non-null object\n",
      "Auction                              41432 non-null object\n",
      "VehYear                              41432 non-null float64\n",
      "Make                                 41432 non-null object\n",
      "Color                                41432 non-null object\n",
      "Transmission                         41432 non-null object\n",
      "WheelTypeID                          41432 non-null object\n",
      "WheelType                            41380 non-null object\n",
      "VehOdo                               41432 non-null float64\n",
      "Nationality                          41432 non-null object\n",
      "Size                                 41432 non-null object\n",
      "TopThreeAmericanName                 41432 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    41416 non-null object\n",
      "MMRAcquisitionAuctionCleanPrice      41429 non-null object\n",
      "MMRAcquisitionRetailAveragePrice     41429 non-null object\n",
      "MMRAcquisitonRetailCleanPrice        41327 non-null object\n",
      "MMRCurrentAuctionAveragePrice        41429 non-null object\n",
      "MMRCurrentAuctionCleanPrice          41429 non-null object\n",
      "MMRCurrentRetailAveragePrice         41409 non-null object\n",
      "MMRCurrentRetailCleanPrice           41409 non-null object\n",
      "MMRCurrentRetailRatio                41116 non-null object\n",
      "PRIMEUNIT                            41432 non-null object\n",
      "AUCGUART                             41432 non-null object\n",
      "VNST                                 41432 non-null object\n",
      "VehBCost                             41432 non-null object\n",
      "IsOnlineSale                         41432 non-null object\n",
      "WarrantyCost                         41432 non-null float64\n",
      "ForSale                              41432 non-null object\n",
      "IsBadBuy                             41432 non-null int64\n",
      "dtypes: float64(3), int64(3), object(25)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data_prep()\n",
    "\n",
    "# separating the y_label -- prediction set\n",
    "y = df['IsBadBuy']\n",
    "\n",
    "#X -features are all column except y\n",
    "X = df.drop(['IsBadBuy'], axis = 1)\n",
    "\n",
    "#X.drop(['Color'], 1, inplace=True)\n",
    "#X.drop(['Size'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Transmission', 'VehOdo', 'MMRAcquisitionAuctionAveragePrice',\n",
       "       'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice',\n",
       "       'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice',\n",
       "       'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice',\n",
       "       'MMRCurrentRetailCleanPrice',\n",
       "       ...\n",
       "       'VNST_OK', 'VNST_OR', 'VNST_PA', 'VNST_SC', 'VNST_TN', 'VNST_TX',\n",
       "       'VNST_UT', 'VNST_VA', 'VNST_WA', 'VNST_WV'],\n",
       "      dtype='object', length=127)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#labelEncoder = LabelEncoder()\n",
    "\n",
    "#categorical_feature_mask = df_final.dtypes==object\n",
    "#categorical_cols = df_final.columns[categorical_feature_mask].tolist()\n",
    "#df_final[categorical_cols] = df_final[categorical_cols].apply(lambda col: labelEncoder.fit_transform(col))\n",
    "#df_final.values[:,7] = labelEncoder.fit_transform(df_final.values[:,7])\n",
    "\n",
    "#df_final\n",
    "\n",
    "# set the random seed - consistent\n",
    "rs = 10\n",
    "\n",
    "# train test split\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.3, stratify=y, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scalering value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0. 49954.  5480. ...     0.     0.     0.]\n",
      " [    0. 72271.  3085. ...     0.     0.     0.]\n",
      " [    0. 79902.  8904. ...     0.     0.     0.]\n",
      " ...\n",
      " [    0. 59196.  5713. ...     0.     0.     0.]\n",
      " [    0. 70977.  5543. ...     0.     0.     0.]\n",
      " [    0. 95711.  3684. ...     0.     0.     0.]]\n",
      "\n",
      "---After Scaling----\n",
      "\n",
      "[[-0.19494723 -1.49555545 -0.18171103 ... -0.24306512 -0.02827485\n",
      "  -0.0365124 ]\n",
      " [-0.19494723 -0.00756551 -1.11425493 ... -0.24306512 -0.02827485\n",
      "  -0.0365124 ]\n",
      " [-0.19494723  0.50123278  1.15149579 ... -0.24306512 -0.02827485\n",
      "  -0.0365124 ]\n",
      " ...\n",
      " [-0.19494723 -0.87934346 -0.09098755 ... -0.24306512 -0.02827485\n",
      "  -0.0365124 ]\n",
      " [-0.19494723 -0.09384319 -0.15718065 ... -0.24306512 -0.02827485\n",
      "  -0.0365124 ]\n",
      " [-0.19494723  1.55530066 -0.88102161 ... -0.24306512 -0.02827485\n",
      "  -0.0365124 ]]\n"
     ]
    }
   ],
   "source": [
    "# initialise a standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "print(\"\\n---After Scaling----\\n\")\n",
    "\n",
    "# learn the mean and std.dev of variables from training data\n",
    "# then use the learned values to transform training data\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "\n",
    "# use the statistic that you learned from training to transform test data\n",
    "# NEVER learn from test data, this is supposed to be a set of dataset\n",
    "# that the model has never seen before\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=10, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=rs)\n",
    "\n",
    "# fit it to training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate first Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825455997869791\n",
      "Test accuracy: 0.8232370301335818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1609\n",
      "           1       0.90      0.73      0.80      1610\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3219\n",
      "   macro avg       0.84      0.82      0.82      3219\n",
      "weighted avg       0.84      0.82      0.82      3219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and test accuracy\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "# classification report on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Get the top 20 most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auction_ADESA : 2.065851504575421\n",
      "VNST_AZ : 1.805182869101257\n",
      "MMRAcquisitionAuctionAveragePrice : -1.37992404991772\n",
      "VNST_OK : 1.270017379068819\n",
      "MMRAcquisitionRetailAveragePrice : 1.2257218833454477\n",
      "Auction_OTHER : -0.9038357728845241\n",
      "Auction_MANHEIM : -0.8392271867435732\n",
      "VNST_CO : -0.8096564618373743\n",
      "MMRCurrentAuctionAveragePrice : 0.679323283592787\n",
      "VNST_PA : 0.6694695437702735\n",
      "VehYear_2008.0 : -0.6623593399693878\n",
      "MMRAcquisitionAuctionCleanPrice : 0.5918379921767993\n",
      "VNST_MO : 0.5705180952109038\n",
      "VNST_TX : -0.5348740698509492\n",
      "VNST_FL : -0.4850539207657993\n",
      "VNST_GA : -0.4633858608024842\n",
      "VNST_VA : -0.45474847890695513\n",
      "VNST_MS : 0.42848951730205165\n",
      "MMRCurrentRetailCleanPrice : -0.4200591154538043\n",
      "VNST_NJ : 0.37945108997382265\n"
     ]
    }
   ],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "coef = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Train accuracy: 0.825455997869791\n",
      "Test accuracy: 0.8232370301335818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1609\n",
      "           1       0.90      0.73      0.80      1610\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3219\n",
      "   macro avg       0.84      0.82      0.82      3219\n",
      "weighted avg       0.84      0.82      0.82      3219\n",
      "\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "#params = {'C' : [1.4111, 1.4112, 1.4113, 1.4114], 'penalty': ['l1','l2'],\n",
    "          #'dual':[False], 'multi_class':['ovr'], 'solver':[ 'liblinear', 'sag', 'saga']},\n",
    "#params = {'penalty':['l1','l2'],'C':[1.4111],'solver':['liblinear'],'multi_class':['ovr']}\n",
    "#,{'penalty':['l2'],'C':[1.4111],'solver':['lbfgs'],'multi_class':['ovr','multinomial']}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs, verbose=True), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Train accuracy: 0.8253228598056185\n",
      "Test accuracy: 0.8235476856166511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1609\n",
      "           1       0.90      0.73      0.81      1610\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3219\n",
      "   macro avg       0.84      0.82      0.82      3219\n",
      "weighted avg       0.84      0.82      0.82      3219\n",
      "\n",
      "{'C': 1.4, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C' : [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9], 'penalty': ['l1','l2']}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs, verbose=True), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.825455997869791\n",
      "Test accuracy: 0.8229263746505125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1609\n",
      "           1       0.90      0.73      0.80      1610\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3219\n",
      "   macro avg       0.83      0.82      0.82      3219\n",
      "weighted avg       0.83      0.82      0.82      3219\n",
      "\n",
      "{'C': 1.3, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C' : [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9], 'penalty': ['l2'], 'solver':['newton-cg', 'lbfgs', 'sag']}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs, verbose=True), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE RFE on Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature set 126\n",
      "Number of features after elimination 44\n"
     ]
    }
   ],
   "source": [
    "rfe = RFECV(estimator = LogisticRegression(random_state=rs, solver = 'lbfgs', max_iter = 200), cv=10)\n",
    "rfe.fit(X_train, y_train) # run the RFECV\n",
    "\n",
    "# comparing how many variables before and after\n",
    "print(\"Original feature set\", X_train.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only the important features\n",
    "X_train_rfe = rfe.transform(X_train)\n",
    "X_test_rfe = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VehOdo', 'MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailCleanPrice', 'VehBCost', 'Auction_ADESA', 'Auction_MANHEIM', 'Auction_OTHER', 'VehYear_2001.0', 'VehYear_2002.0', 'VehYear_2006.0', 'VehYear_2007.0', 'VehYear_2008.0', 'Make_ACURA', 'Make_SUZUKI', 'Color_NOT AVAIL', 'WheelType_Alloy', 'TopThreeAmericanName_FORD', 'VNST_AL', 'VNST_AZ', 'VNST_CA', 'VNST_CO', 'VNST_FL', 'VNST_GA', 'VNST_KY', 'VNST_LA', 'VNST_MO', 'VNST_MS', 'VNST_NC', 'VNST_NH', 'VNST_NJ', 'VNST_NM', 'VNST_NV', 'VNST_OK', 'VNST_OR', 'VNST_PA', 'VNST_TX', 'VNST_UT', 'VNST_VA', 'VNST_WA', 'VNST_WV']\n"
     ]
    }
   ],
   "source": [
    "# The selected features from RFE\n",
    "feature_importance = list(zip(X.columns, rfe.support_))\n",
    "new_features = []\n",
    "for key,value in enumerate(feature_importance):\n",
    "    if(value[1]) == True:\n",
    "        new_features.append(value[0])\n",
    "        \n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Train accuracy: 0.825722273998136\n",
      "Test accuracy: 0.8219944082013048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      1609\n",
      "           1       0.90      0.72      0.80      1610\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3219\n",
      "   macro avg       0.84      0.82      0.82      3219\n",
      "weighted avg       0.84      0.82      0.82      3219\n",
      "\n",
      "{'C': 1.0, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C' : [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9], 'penalty': ['l1','l2']}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs, verbose=True), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_rfe, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train_rfe, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test_rfe, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test_rfe)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMRCurrentRetailAveragePrice : 2.0672111164595557\n",
      "VehYear_2007.0 : 1.8234128504891336\n",
      "Make_INFINITI : 1.3823767871813302\n",
      "VehOdo : -1.3458998141220209\n",
      "MMRAcquisitionAuctionCleanPrice : 1.1287376120086121\n",
      "MMRCurrentRetailRatio : -0.9054728026388369\n",
      "MMRCurrentRetailCleanPrice : -0.8389101323172613\n",
      "Auction_OTHER : -0.7859982531009929\n",
      "Make_JEEP : 0.7506545015937736\n",
      "Make_CHEVROLET : 0.6429702499552219\n",
      "MMRAcquisitionAuctionAveragePrice : 0.5923142485237657\n",
      "MMRCurrentAuctionAveragePrice : -0.5790049081542791\n",
      "MMRAcquisitionRetailAveragePrice : 0.531617299538697\n",
      "Make_DODGE : 0.5304218713789429\n",
      "VehYear_2009.0 : -0.5074318693354968\n",
      "VehYear_2008.0 : 0.48389871704137\n",
      "Make_CHRYSLER : 0.47008441291627184\n",
      "Make_GMC : 0.428219962377493\n",
      "Make_HYUNDAI : 0.34817368574598895\n",
      "MMRCurrentAuctionCleanPrice : -0.33076641236558174\n"
     ]
    }
   ],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "importances = cv.best_params_\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Get Log of each variables - not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41432 entries, 0 to 41475\n",
      "Data columns (total 31 columns):\n",
      "PurchaseID                           41432 non-null int64\n",
      "PurchaseTimestamp                    41432 non-null int64\n",
      "PurchaseDate                         41432 non-null object\n",
      "Auction                              41432 non-null object\n",
      "VehYear                              41432 non-null float64\n",
      "Make                                 41432 non-null object\n",
      "Color                                41432 non-null object\n",
      "Transmission                         41432 non-null object\n",
      "WheelTypeID                          41432 non-null object\n",
      "WheelType                            41380 non-null object\n",
      "VehOdo                               41432 non-null float64\n",
      "Nationality                          41432 non-null object\n",
      "Size                                 41432 non-null object\n",
      "TopThreeAmericanName                 41432 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    41416 non-null object\n",
      "MMRAcquisitionAuctionCleanPrice      41429 non-null object\n",
      "MMRAcquisitionRetailAveragePrice     41429 non-null object\n",
      "MMRAcquisitonRetailCleanPrice        41327 non-null object\n",
      "MMRCurrentAuctionAveragePrice        41429 non-null object\n",
      "MMRCurrentAuctionCleanPrice          41429 non-null object\n",
      "MMRCurrentRetailAveragePrice         41409 non-null object\n",
      "MMRCurrentRetailCleanPrice           41409 non-null object\n",
      "MMRCurrentRetailRatio                41116 non-null object\n",
      "PRIMEUNIT                            41432 non-null object\n",
      "AUCGUART                             41432 non-null object\n",
      "VNST                                 41432 non-null object\n",
      "VehBCost                             41432 non-null object\n",
      "IsOnlineSale                         41432 non-null object\n",
      "WarrantyCost                         41432 non-null float64\n",
      "ForSale                              41432 non-null object\n",
      "IsBadBuy                             41432 non-null int64\n",
      "dtypes: float64(3), int64(3), object(25)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = data_prep()\n",
    "\n",
    "# separating the y_label -- prediction set\n",
    "y_log = df['IsBadBuy']\n",
    "\n",
    "#X -features are all column except y\n",
    "X_log = df.drop(['IsBadBuy'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list columns to be transformed\n",
    "columns_to_transform = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice', 'MMRAcquisitionRetailAveragePrice',\n",
    "                        'MMRAcquisitonRetailCleanPrice', 'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice', 'MMRCurrentRetailAveragePrice','MMRCurrentRetailCleanPrice','VehBCost']\n",
    "\n",
    "# transform the columns with np.log\n",
    "for col in columns_to_transform:\n",
    "    X_log[col] = X_log[col].apply(lambda x: x+1)\n",
    "    X_log[col] = X_log[col].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lexi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create X, y and train test data partitions\n",
    "X_mat_log = X_log.as_matrix()\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_mat_log, y_log, test_size=0.3, stratify=y_log, \n",
    "                                                                    random_state=rs)\n",
    "\n",
    "# standardise them again\n",
    "scaler_log = StandardScaler()\n",
    "X_train_log = scaler_log.fit_transform(X_train_log, y_train_log)\n",
    "X_test_log = scaler_log.transform(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8242577552922381\n",
      "Test accuracy: 0.8207517862690277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84      1609\n",
      "           1       0.90      0.73      0.80      1610\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      3219\n",
      "   macro avg       0.83      0.82      0.82      3219\n",
      "weighted avg       0.83      0.82      0.82      3219\n",
      "\n",
      "{'C': 1.4111, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C' : [1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9], 'penalty': ['l1','l2']}\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_log, y_train_log)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train_log, y_train_log))\n",
    "print(\"Test accuracy:\", cv.score(X_test_log, y_test_log))\n",
    "\n",
    "y_pred = cv.predict(X_test_log)\n",
    "print(classification_report(y_test_log, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
